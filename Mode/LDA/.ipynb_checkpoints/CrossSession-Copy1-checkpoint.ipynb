{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_1_mav</th>\n",
       "      <th>channel_1_mav2</th>\n",
       "      <th>channel_1_rms</th>\n",
       "      <th>channel_1_iav</th>\n",
       "      <th>channel_1_ssi</th>\n",
       "      <th>channel_1_var</th>\n",
       "      <th>channel_1_wl</th>\n",
       "      <th>channel_1_iemg</th>\n",
       "      <th>channel_1_aac</th>\n",
       "      <th>channel_1_zc</th>\n",
       "      <th>...</th>\n",
       "      <th>channel_7_aac</th>\n",
       "      <th>channel_7_zc</th>\n",
       "      <th>channel_7_ssc</th>\n",
       "      <th>channel_7_wamp</th>\n",
       "      <th>channel_7_medf</th>\n",
       "      <th>channel_7_meanf</th>\n",
       "      <th>userID</th>\n",
       "      <th>sessionID</th>\n",
       "      <th>uttID</th>\n",
       "      <th>modeID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034982</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.047836</td>\n",
       "      <td>117.153433</td>\n",
       "      <td>7.663511</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>131.601251</td>\n",
       "      <td>117.153433</td>\n",
       "      <td>0.039296</td>\n",
       "      <td>1239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.934334e-07</td>\n",
       "      <td>122</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>41.441441</td>\n",
       "      <td>53.265246</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010001</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028157</td>\n",
       "      <td>0.027672</td>\n",
       "      <td>0.040353</td>\n",
       "      <td>63.465079</td>\n",
       "      <td>3.670272</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>71.151924</td>\n",
       "      <td>63.465079</td>\n",
       "      <td>0.031567</td>\n",
       "      <td>861</td>\n",
       "      <td>...</td>\n",
       "      <td>2.722643e-07</td>\n",
       "      <td>77</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>38.839286</td>\n",
       "      <td>51.119716</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010002</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035103</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>0.049304</td>\n",
       "      <td>142.411421</td>\n",
       "      <td>9.862262</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>160.962810</td>\n",
       "      <td>142.411421</td>\n",
       "      <td>0.039675</td>\n",
       "      <td>1552</td>\n",
       "      <td>...</td>\n",
       "      <td>1.546840e-07</td>\n",
       "      <td>150</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>43.811881</td>\n",
       "      <td>58.339405</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010003</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032311</td>\n",
       "      <td>0.032216</td>\n",
       "      <td>0.044599</td>\n",
       "      <td>134.576651</td>\n",
       "      <td>8.284614</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>151.073407</td>\n",
       "      <td>134.576651</td>\n",
       "      <td>0.036272</td>\n",
       "      <td>1551</td>\n",
       "      <td>...</td>\n",
       "      <td>1.484281e-07</td>\n",
       "      <td>154</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>38.313253</td>\n",
       "      <td>51.176996</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010004</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030766</td>\n",
       "      <td>0.030463</td>\n",
       "      <td>0.044142</td>\n",
       "      <td>144.633076</td>\n",
       "      <td>9.159818</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>161.532869</td>\n",
       "      <td>144.633076</td>\n",
       "      <td>0.034361</td>\n",
       "      <td>1743</td>\n",
       "      <td>...</td>\n",
       "      <td>1.378023e-07</td>\n",
       "      <td>179</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>40.938166</td>\n",
       "      <td>53.242317</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010005</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>0.024542</td>\n",
       "      <td>0.024433</td>\n",
       "      <td>0.041126</td>\n",
       "      <td>57.330769</td>\n",
       "      <td>3.950974</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>49.749426</td>\n",
       "      <td>57.330769</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>674</td>\n",
       "      <td>...</td>\n",
       "      <td>2.775535e-07</td>\n",
       "      <td>76</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>41.379310</td>\n",
       "      <td>53.166785</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190246</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>0.016662</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.024829</td>\n",
       "      <td>31.741925</td>\n",
       "      <td>1.174369</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>28.414596</td>\n",
       "      <td>31.741925</td>\n",
       "      <td>0.014916</td>\n",
       "      <td>542</td>\n",
       "      <td>...</td>\n",
       "      <td>3.393484e-07</td>\n",
       "      <td>73</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>41.269841</td>\n",
       "      <td>53.166460</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190247</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>0.019216</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>43.312481</td>\n",
       "      <td>1.685064</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>38.049582</td>\n",
       "      <td>43.312481</td>\n",
       "      <td>0.016881</td>\n",
       "      <td>634</td>\n",
       "      <td>...</td>\n",
       "      <td>2.852185e-07</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>41.517857</td>\n",
       "      <td>53.280330</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190248</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>0.015547</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>26.616147</td>\n",
       "      <td>0.860052</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>24.287830</td>\n",
       "      <td>26.616147</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>521</td>\n",
       "      <td>...</td>\n",
       "      <td>3.766394e-07</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>40.588235</td>\n",
       "      <td>53.132213</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190249</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0.019752</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.027330</td>\n",
       "      <td>38.693980</td>\n",
       "      <td>1.463215</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>35.091411</td>\n",
       "      <td>38.693980</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>595</td>\n",
       "      <td>...</td>\n",
       "      <td>3.295911e-07</td>\n",
       "      <td>71</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>40.206186</td>\n",
       "      <td>53.312535</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190250</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel_1_mav  channel_1_mav2  channel_1_rms  channel_1_iav  \\\n",
       "0          0.034982        0.034978       0.047836     117.153433   \n",
       "1          0.028157        0.027672       0.040353      63.465079   \n",
       "2          0.035103        0.034888       0.049304     142.411421   \n",
       "3          0.032311        0.032216       0.044599     134.576651   \n",
       "4          0.030766        0.030463       0.044142     144.633076   \n",
       "...             ...             ...            ...            ...   \n",
       "4795       0.024542        0.024433       0.041126      57.330769   \n",
       "4796       0.016662        0.016508       0.024829      31.741925   \n",
       "4797       0.019216        0.018951       0.027342      43.312481   \n",
       "4798       0.015547        0.015341       0.022414      26.616147   \n",
       "4799       0.019752        0.019547       0.027330      38.693980   \n",
       "\n",
       "      channel_1_ssi  channel_1_var  channel_1_wl  channel_1_iemg  \\\n",
       "0          7.663511       0.002288    131.601251      117.153433   \n",
       "1          3.670272       0.001628     71.151924       63.465079   \n",
       "2          9.862262       0.002431    160.962810      142.411421   \n",
       "3          8.284614       0.001989    151.073407      134.576651   \n",
       "4          9.159818       0.001948    161.532869      144.633076   \n",
       "...             ...            ...           ...             ...   \n",
       "4795       3.950974       0.001691     49.749426       57.330769   \n",
       "4796       1.174369       0.000616     28.414596       31.741925   \n",
       "4797       1.685064       0.000748     38.049582       43.312481   \n",
       "4798       0.860052       0.000502     24.287830       26.616147   \n",
       "4799       1.463215       0.000747     35.091411       38.693980   \n",
       "\n",
       "      channel_1_aac  channel_1_zc  ...  channel_7_aac  channel_7_zc  \\\n",
       "0          0.039296          1239  ...   1.934334e-07           122   \n",
       "1          0.031567           861  ...   2.722643e-07            77   \n",
       "2          0.039675          1552  ...   1.546840e-07           150   \n",
       "3          0.036272          1551  ...   1.484281e-07           154   \n",
       "4          0.034361          1743  ...   1.378023e-07           179   \n",
       "...             ...           ...  ...            ...           ...   \n",
       "4795       0.021297           674  ...   2.775535e-07            76   \n",
       "4796       0.014916           542  ...   3.393484e-07            73   \n",
       "4797       0.016881           634  ...   2.852185e-07            85   \n",
       "4798       0.014187           521  ...   3.766394e-07            60   \n",
       "4799       0.017913           595  ...   3.295911e-07            71   \n",
       "\n",
       "      channel_7_ssc  channel_7_wamp  channel_7_medf  channel_7_meanf  userID  \\\n",
       "0               143               0       41.441441        53.265246       1   \n",
       "1                97               0       38.839286        51.119716       1   \n",
       "2               169               0       43.811881        58.339405       1   \n",
       "3               180               0       38.313253        51.176996       1   \n",
       "4               203               0       40.938166        53.242317       1   \n",
       "...             ...             ...             ...              ...     ...   \n",
       "4795            104               0       41.379310        53.166785       8   \n",
       "4796             82               0       41.269841        53.166460       8   \n",
       "4797            105               0       41.517857        53.280330       8   \n",
       "4798             69               0       40.588235        53.132213       8   \n",
       "4799             80               0       40.206186        53.312535       8   \n",
       "\n",
       "      sessionID     uttID   modeID  \n",
       "0          1001  10010001  audible  \n",
       "1          1001  10010002  audible  \n",
       "2          1001  10010003  audible  \n",
       "3          1001  10010004  audible  \n",
       "4          1001  10010005  audible  \n",
       "...         ...       ...      ...  \n",
       "4795       8019  80190246  whisper  \n",
       "4796       8019  80190247  whisper  \n",
       "4797       8019  80190248  whisper  \n",
       "4798       8019  80190249  whisper  \n",
       "4799       8019  80190250  whisper  \n",
       "\n",
       "[4800 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.fftpack import fftn, ifftn, fft, ifft\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') \n",
    "#df = pd.read_csv(\"features/Features10too200hz.csv\")\n",
    "\n",
    "#df = pd.read_csv(\"features/unfilteredFeatures.csv\")\n",
    "\n",
    "df = pd.read_csv(\"featuress/allEmgData10to200hz_noAudible.csv\")\n",
    "\n",
    "#df = pd.read_csv(\"Features_all_no_audible.csv\")\n",
    "#df = df[(df.modeID != 'audible')]\n",
    "#df= df[df.sessionID == 4002 ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_per_session(session_id):\n",
    "    temp_df = df[(df.sessionID == session_id)]\n",
    "    data = temp_df.copy()\n",
    "    data = shuffle(data)\n",
    "    y = data['modeID']\n",
    "    data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "def split_data_session(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['sessionID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['sessionID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def split_data_utterance(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['userID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['userID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def split_data(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['userID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['userID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_user1_session1():\n",
    "    train_ids = [1002,1003]\n",
    "    test_ids = [1001]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 1 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test \n",
    "    \n",
    "def lda_user1_session2():\n",
    "    train_ids = [1001,1003]\n",
    "    test_ids = [1002]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 2 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test \n",
    "    \n",
    "def lda_user1_session3():\n",
    "    train_ids = [1001,1002]\n",
    "    test_ids = [1003]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 3 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test \n",
    "    \n",
    "def lda_user2_session1():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, \n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2001]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 1 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user2_session3():\n",
    "    train_ids = [2001, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2003]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 3 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user2_session4():\n",
    "    train_ids = [2003, 2001, 2005, 2006, 2007, 2008, 2009, 2010, 2012,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2004]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 4 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test     \n",
    "    \n",
    "def lda_user2_session5():\n",
    "    train_ids = [2003, 2004, 2001, 2006, 2007, 2008, 2009, 2010, 2012,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2005]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 5 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user2_session6():\n",
    "    train_ids = [2003, 2004, 2005, 2001, 2007, 2008, 2009, 2010, 2012,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2006]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 6 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test    \n",
    "    \n",
    "def lda_user2_session7():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2001, 2008, 2009, 2010, 2012,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2007]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 7 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test     \n",
    "    \n",
    "def lda_user2_session8():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2001, 2009, 2010, 2012,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2008]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 8 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user2_session9():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2001, 2010, 2012,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2009]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 9 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test    \n",
    "    \n",
    "def lda_user2_session10():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2001, 2012,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2010]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 10 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test      \n",
    "    \n",
    "def lda_user2_session12():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2001,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2012]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 12 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user2_session13():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2028, 2029,  2032] \n",
    "    test_ids = [2013]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 13 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test    \n",
    "    \n",
    "def lda_user2_session28():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2029,  2032] \n",
    "    test_ids = [2028]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 28 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user2_session29():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2028,  2032] \n",
    "    test_ids = [2029]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 29 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test     \n",
    "    \n",
    "def lda_user2_session31():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2028, 2029, 2032] \n",
    "    test_ids = [2031]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 31 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test   \n",
    "    \n",
    "def lda_user2_session32():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2028, 2029,  2013] \n",
    "    test_ids = [2032]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 32 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user4_session1():\n",
    "    train_ids = [4002]\n",
    "    test_ids = [4001]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 1 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test    \n",
    "    \n",
    "def lda_user4_session2():\n",
    "    train_ids = [4001]\n",
    "    test_ids = [4002]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 2 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test \n",
    "    \n",
    "def lda_user7_session1():\n",
    "    train_ids = [7002]\n",
    "    test_ids = [7001]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 1 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user7_session2():\n",
    "    train_ids = [7001]\n",
    "    test_ids = [7002]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 2 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test  \n",
    "    \n",
    "def lda_user8_session2():\n",
    "    train_ids = [8003, 8010, 8016, 8017, 8018, 8019]\n",
    "    test_ids = [8002]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 2 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test    \n",
    "    \n",
    "def lda_user8_session3():\n",
    "    train_ids = [8002, 8010, 8016, 8017, 8018, 8019]\n",
    "    test_ids = [8003]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 3 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test   \n",
    "    \n",
    "def lda_user8_session10():\n",
    "    train_ids = [8003, 8002, 8016, 8017, 8018, 8019]\n",
    "    test_ids = [8010]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 10 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test    \n",
    "    \n",
    "def lda_user8_session16():\n",
    "    train_ids = [8003, 8010, 8002, 8017, 8018, 8019]\n",
    "    test_ids = [8016]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 16 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test    \n",
    "    \n",
    "def lda_user8_session17():\n",
    "    train_ids = [8003, 8010, 8016, 8002, 8018, 8019]\n",
    "    test_ids = [8017]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 17 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test   \n",
    "    \n",
    "def lda_user8_session18():\n",
    "    train_ids = [8003, 8010, 8016, 8017, 8002, 8019]\n",
    "    test_ids = [8018]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 18 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test      \n",
    "    \n",
    "def lda_user8_session19():\n",
    "    train_ids = [8003, 8010, 8016, 8017, 8018, 8002]\n",
    "    test_ids = [8019]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 19 is \"+str(score))\n",
    "    a=np.unique(k_clf.predict(X_test))\n",
    "    #plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "    #plt.title(\"User\" + str(test_ids[0]))\n",
    "    #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    b=k_clf.predict(X_test)\n",
    "    return b,y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda():\n",
    "    #ids = [1001,1002,1003,2001,2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2013,\n",
    "       #2028, 2029, 2031, 2032,4001,4002,7001,7002,8002,8003, 8010, 8016, 8017, 8018, 8019]\n",
    "    ids = [ 8010, 8016, 8017, 8018, 8019]\n",
    "    scores = np.array([])\n",
    "    for x in range (len(ids)):\n",
    "        test_ids = []\n",
    "        test_ids = ids[x:x+1]\n",
    "        train_ids = np.delete(ids,x)\n",
    "        #print (test_ids)\n",
    "        X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "        k_clf = LinearDiscriminantAnalysis()\n",
    "        k_clf.fit(X_train, y_train)\n",
    "        score = k_clf.score(X_test, y_test)\n",
    "        sscore = np.array([score])\n",
    "        scores = np.concatenate([scores,sscore],axis=0)\n",
    "        a=np.unique(k_clf.predict(X_test))\n",
    "        plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "        plt.title(\"User\" + str(test_ids[0]))\n",
    "        #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"Accuracy for session \" + str(test_ids) +\" is \"+str(score))\n",
    "    print (\"Durchschnitt: \")\n",
    "    print((scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_all():\n",
    "    print (\"User 1 : \" )\n",
    "    a = lda_user1_session1()\n",
    "    b = lda_user1_session2()\n",
    "    c = lda_user1_session3()\n",
    "    print (\"User 2 : \" )\n",
    "    d = lda_user2_session1()\n",
    "    e = lda_user2_session3()\n",
    "    f = lda_user2_session4()\n",
    "    g = lda_user2_session5()\n",
    "    h = lda_user2_session6()\n",
    "    i = lda_user2_session7()\n",
    "    j = lda_user2_session8()\n",
    "    k = lda_user2_session9()\n",
    "    l = lda_user2_session10()\n",
    "    m = lda_user2_session12()\n",
    "    n = lda_user2_session13()\n",
    "    o = lda_user2_session28()\n",
    "    p = lda_user2_session29()\n",
    "    q = lda_user2_session31()\n",
    "    r = lda_user2_session32()\n",
    "    print (\"User 4 : \" )\n",
    "    s = lda_user4_session1()\n",
    "    t = lda_user4_session2()\n",
    "    print (\"User 7 : \" )\n",
    "    u = lda_user7_session1()\n",
    "    v = lda_user7_session2()\n",
    "    print (\"User 8 : \" )\n",
    "    w = lda_user8_session2()\n",
    "    x = lda_user8_session3()\n",
    "    y = lda_user8_session10()\n",
    "    z = lda_user8_session16()\n",
    "    aa = lda_user8_session17()\n",
    "    bb = lda_user8_session18()\n",
    "    cc = lda_user8_session19()\n",
    "    scores = np.array([a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,p,q,r,s,t,u,v,w,x,y,z,aa,bb,cc])\n",
    "    print(\"Durchschnitt:\")\n",
    "    print((scores.mean()))\n",
    "    print(scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 : \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f21f23892424>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlda_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-b1be471f04a9>\u001b[0m in \u001b[0;36mlda_all\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlda_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"User 1 : \"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_user1_session1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_user1_session2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_user1_session3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-08880d82e6fa>\u001b[0m in \u001b[0;36mlda_user1_session1\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mk_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m290\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mk_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "lda_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "def lda_allss():\n",
    "    y_pred =[]\n",
    "    y_actu=[]\n",
    "    labels = ['audible', 'silent','whisper']\n",
    "    print (\"User 1 : \" )\n",
    "    y_p,y_a = lda_user1_session1()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user1_session2()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user1_session3()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    print (\"User 2 : \" )\n",
    "    y_p,y_a = lda_user2_session1()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session3()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session4()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session5()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session6()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session7()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session8()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session9()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session10()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session12()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session13()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session28()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session29()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session31()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user2_session32()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    print (\"User 4 : \" )\n",
    "    y_p,y_a = lda_user4_session1()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user4_session2()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    print (\"User 7 : \" )\n",
    "    y_p,y_a = lda_user7_session1()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user7_session2()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    print (\"User 8 : \" )\n",
    "    y_p,y_a = lda_user8_session2()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user8_session3()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user8_session10()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user8_session16()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user8_session17()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user8_session18()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    y_p,y_a = lda_user8_session19()\n",
    "    y_pred =np.concatenate((y_pred, y_p))\n",
    "    y_actu =np.concatenate((y_actu, y_a))\n",
    "    a = confusion_matrix(y_actu, y_pred, labels=labels,normalize='true')\n",
    "    plt.figure()\n",
    "    cm_display = ConfusionMatrixDisplay(a,display_labels=labels).plot()\n",
    "    plt.title(\"Speechmode\")\n",
    "    plt.savefig(os.path.join(\"AllSessionModeConfMatUnf.png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "    #scores = np.array([a,b,c,d,e,f,g,h,i,j,k,l,m,o,p,p,q,r,s,t,u,v,w,x,y,z,aa,bb,cc])\n",
    "    #print(\"Durchschnitt:\")\n",
    "    #print((scores.mean()))\n",
    "    #print(scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 : \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f21f23892424>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlda_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-b1be471f04a9>\u001b[0m in \u001b[0;36mlda_all\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlda_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"User 1 : \"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_user1_session1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_user1_session2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_user1_session3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-08880d82e6fa>\u001b[0m in \u001b[0;36mlda_user1_session1\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mk_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m290\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mk_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "lda_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
