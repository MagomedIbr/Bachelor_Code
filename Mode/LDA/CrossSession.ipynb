{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magomed\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_1_mav</th>\n",
       "      <th>channel_1_mav2</th>\n",
       "      <th>channel_1_rms</th>\n",
       "      <th>channel_1_iav</th>\n",
       "      <th>channel_1_ssi</th>\n",
       "      <th>channel_1_var</th>\n",
       "      <th>channel_1_wl</th>\n",
       "      <th>channel_1_iemg</th>\n",
       "      <th>channel_1_aac</th>\n",
       "      <th>channel_1_zc</th>\n",
       "      <th>...</th>\n",
       "      <th>channel_7_aac</th>\n",
       "      <th>channel_7_zc</th>\n",
       "      <th>channel_7_ssc</th>\n",
       "      <th>channel_7_wamp</th>\n",
       "      <th>channel_7_medf</th>\n",
       "      <th>channel_7_meanf</th>\n",
       "      <th>userID</th>\n",
       "      <th>sessionID</th>\n",
       "      <th>uttID</th>\n",
       "      <th>modeID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067106</td>\n",
       "      <td>0.067103</td>\n",
       "      <td>0.081097</td>\n",
       "      <td>224.738037</td>\n",
       "      <td>22.025275</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>191.597839</td>\n",
       "      <td>224.738037</td>\n",
       "      <td>0.057210</td>\n",
       "      <td>682</td>\n",
       "      <td>...</td>\n",
       "      <td>7.289956e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010001</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063718</td>\n",
       "      <td>0.063648</td>\n",
       "      <td>0.075014</td>\n",
       "      <td>143.621399</td>\n",
       "      <td>12.683361</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>103.957947</td>\n",
       "      <td>143.621399</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>288</td>\n",
       "      <td>...</td>\n",
       "      <td>1.083144e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014499</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010002</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067169</td>\n",
       "      <td>0.067090</td>\n",
       "      <td>0.081422</td>\n",
       "      <td>272.503754</td>\n",
       "      <td>26.896239</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>227.992035</td>\n",
       "      <td>272.503754</td>\n",
       "      <td>0.056197</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>6.017763e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010003</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065079</td>\n",
       "      <td>0.065007</td>\n",
       "      <td>0.078301</td>\n",
       "      <td>271.053162</td>\n",
       "      <td>25.535573</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>224.132660</td>\n",
       "      <td>271.053162</td>\n",
       "      <td>0.053813</td>\n",
       "      <td>772</td>\n",
       "      <td>...</td>\n",
       "      <td>5.861720e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015302</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010004</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065251</td>\n",
       "      <td>0.065301</td>\n",
       "      <td>0.077894</td>\n",
       "      <td>306.745789</td>\n",
       "      <td>28.522983</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>239.254150</td>\n",
       "      <td>306.745789</td>\n",
       "      <td>0.050894</td>\n",
       "      <td>756</td>\n",
       "      <td>...</td>\n",
       "      <td>5.193376e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>10010005</td>\n",
       "      <td>audible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>0.105939</td>\n",
       "      <td>0.105920</td>\n",
       "      <td>0.114247</td>\n",
       "      <td>247.473846</td>\n",
       "      <td>30.490382</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>61.923187</td>\n",
       "      <td>247.473846</td>\n",
       "      <td>0.026508</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.045123e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014826</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190246</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>0.103561</td>\n",
       "      <td>0.103695</td>\n",
       "      <td>0.107324</td>\n",
       "      <td>197.284485</td>\n",
       "      <td>21.942521</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>36.726807</td>\n",
       "      <td>197.284485</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.281578e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190247</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.103751</td>\n",
       "      <td>0.108278</td>\n",
       "      <td>234.181610</td>\n",
       "      <td>26.425943</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>47.587830</td>\n",
       "      <td>234.181610</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.083144e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190248</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>0.103268</td>\n",
       "      <td>0.103307</td>\n",
       "      <td>0.106641</td>\n",
       "      <td>176.794922</td>\n",
       "      <td>19.469253</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>32.907990</td>\n",
       "      <td>176.794922</td>\n",
       "      <td>0.019222</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.426055e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190249</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0.104160</td>\n",
       "      <td>0.104060</td>\n",
       "      <td>0.108662</td>\n",
       "      <td>204.049377</td>\n",
       "      <td>23.130756</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>44.460236</td>\n",
       "      <td>204.049377</td>\n",
       "      <td>0.022695</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.246251e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>8</td>\n",
       "      <td>8019</td>\n",
       "      <td>80190250</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel_1_mav  channel_1_mav2  channel_1_rms  channel_1_iav  \\\n",
       "0          0.067106        0.067103       0.081097     224.738037   \n",
       "1          0.063718        0.063648       0.075014     143.621399   \n",
       "2          0.067169        0.067090       0.081422     272.503754   \n",
       "3          0.065079        0.065007       0.078301     271.053162   \n",
       "4          0.065251        0.065301       0.077894     306.745789   \n",
       "...             ...             ...            ...            ...   \n",
       "4795       0.105939        0.105920       0.114247     247.473846   \n",
       "4796       0.103561        0.103695       0.107324     197.284485   \n",
       "4797       0.103896        0.103751       0.108278     234.181610   \n",
       "4798       0.103268        0.103307       0.106641     176.794922   \n",
       "4799       0.104160        0.104060       0.108662     204.049377   \n",
       "\n",
       "      channel_1_ssi  channel_1_var  channel_1_wl  channel_1_iemg  \\\n",
       "0         22.025275       0.003286    191.597839      224.738037   \n",
       "1         12.683361       0.002283    103.957947      143.621399   \n",
       "2         26.896239       0.003316    227.992035      272.503754   \n",
       "3         25.535573       0.002825    224.132660      271.053162   \n",
       "4         28.522983       0.002760    239.254150      306.745789   \n",
       "...             ...            ...           ...             ...   \n",
       "4795      30.490382       0.002267     61.923187      247.473846   \n",
       "4796      21.942521       0.000830     36.726807      197.284485   \n",
       "4797      26.425943       0.000987     47.587830      234.181610   \n",
       "4798      19.469253       0.000728     32.907990      176.794922   \n",
       "4799      23.130756       0.001015     44.460236      204.049377   \n",
       "\n",
       "      channel_1_aac  channel_1_zc  ...  channel_7_aac  channel_7_zc  \\\n",
       "0          0.057210           682  ...   7.289956e-08             0   \n",
       "1          0.046122           288  ...   1.083144e-07             0   \n",
       "2          0.056197           816  ...   6.017763e-08             0   \n",
       "3          0.053813           772  ...   5.861720e-08             0   \n",
       "4          0.050894           756  ...   5.193376e-08             0   \n",
       "...             ...           ...  ...            ...           ...   \n",
       "4795       0.026508            70  ...   1.045123e-07             0   \n",
       "4796       0.019279            10  ...   1.281578e-07             0   \n",
       "4797       0.021113            20  ...   1.083144e-07             0   \n",
       "4798       0.019222             6  ...   1.426055e-07             0   \n",
       "4799       0.022695            20  ...   1.246251e-07             0   \n",
       "\n",
       "      channel_7_ssc  channel_7_wamp  channel_7_medf  channel_7_meanf  userID  \\\n",
       "0                 0               0             0.0         0.014719       1   \n",
       "1                 0               0             0.0         0.014499       1   \n",
       "2                 0               0             0.0         0.015419       1   \n",
       "3                 0               0             0.0         0.015302       1   \n",
       "4                 0               0             0.0         0.014725       1   \n",
       "...             ...             ...             ...              ...     ...   \n",
       "4795              0               0             0.0         0.014826       8   \n",
       "4796              0               0             0.0         0.014841       8   \n",
       "4797              0               0             0.0         0.015300       8   \n",
       "4798              0               0             0.0         0.015288       8   \n",
       "4799              0               0             0.0         0.015121       8   \n",
       "\n",
       "      sessionID     uttID   modeID  \n",
       "0          1001  10010001  audible  \n",
       "1          1001  10010002  audible  \n",
       "2          1001  10010003  audible  \n",
       "3          1001  10010004  audible  \n",
       "4          1001  10010005  audible  \n",
       "...         ...       ...      ...  \n",
       "4795       8019  80190246  whisper  \n",
       "4796       8019  80190247  whisper  \n",
       "4797       8019  80190248  whisper  \n",
       "4798       8019  80190249  whisper  \n",
       "4799       8019  80190250  whisper  \n",
       "\n",
       "[4800 rows x 102 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.fftpack import fftn, ifftn, fft, ifft\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.fftpack import fftn, ifftn, fft, ifft\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "#df = pd.read_csv(\"features/Features10too200hz.csv\")\n",
    "\n",
    "#df = pd.read_csv(\"features/unfilteredFeatures.csv\")\n",
    "#df = pd.read_csv(\"featuress/allEmgData10to200hz_noAudible.csv\")\n",
    "df = pd.read_csv(\"featuress/allEmgData_noAudible.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#df = pd.read_csv(\"Features_all_no_audible.csv\")\n",
    "#df = df[(df.modeID != 'audible')]\n",
    "#df= df[df.sessionID == 4002 ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_per_session(session_id):\n",
    "    temp_df = df[(df.sessionID == session_id)]\n",
    "    data = temp_df.copy()\n",
    "    data = shuffle(data)\n",
    "    y = data['modeID']\n",
    "    data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "def split_data_session(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['sessionID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['sessionID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def split_data_utterance(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['userID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['userID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def split_data(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['userID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['userID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda():\n",
    "    ids = [1001,1002,1003,2001,2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032,4001,4002,7001,7002,8002,8003, 8010, 8016, 8017, 8018, 8019]\n",
    "    #ids = [ 8010, 8016, 8017, 8018, 8019]\n",
    "    scores = np.array([])\n",
    "    for x in range (len(ids)):\n",
    "        test_ids = []\n",
    "        test_ids = ids[x:x+1]\n",
    "        train_ids = np.delete(ids,x)\n",
    "        #print (test_ids)\n",
    "        X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "        k_clf = LinearDiscriminantAnalysis()\n",
    "        k_clf.fit(X_train, y_train)\n",
    "        score = k_clf.score(X_test, y_test)\n",
    "        sscore = np.array([score])\n",
    "        scores = np.concatenate([scores,sscore],axis=0)\n",
    "        a=np.unique(k_clf.predict(X_test))\n",
    "        plot_confusion_matrix(k_clf, X_test, y_test,normalize='true')  # doctest: +SKIP\n",
    "        plt.title(\"User\" + str(test_ids[0]))\n",
    "        #plt.savefig(os.path.join(\"User\" + str(test_ids[0])+\".png\"), dpi=600, format='png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"Accuracy for session \" + str(test_ids) +\" is \"+str(score))\n",
    "    print (\"Durchschnitt: \")\n",
    "    print((scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_user1_session1():\n",
    "    train_ids = [1002,1003]\n",
    "    test_ids = [1001]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 1 is \"+str(score))\n",
    "    return score\n",
    "    \n",
    "def lda_user1_session2():\n",
    "    train_ids = [1001,1003]\n",
    "    test_ids = [1002]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 2 is \"+str(score))\n",
    "    return score\n",
    "    \n",
    "def lda_user1_session3():\n",
    "    train_ids = [1001,1002]\n",
    "    test_ids = [1003]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 3 is \"+str(score))\n",
    "    return score\n",
    "    \n",
    "def lda_user2_session1():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2001]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 1 is \"+str(score))\n",
    "    return score  \n",
    "    \n",
    "def lda_user2_session3():\n",
    "    train_ids = [2001, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2003]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 3 is \"+str(score))\n",
    "    return score \n",
    "    \n",
    "def lda_user2_session4():\n",
    "    train_ids = [2003, 2001, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2004]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 4 is \"+str(score))\n",
    "    return score    \n",
    "    \n",
    "def lda_user2_session5():\n",
    "    train_ids = [2003, 2004, 2001, 2006, 2007, 2008, 2009, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2005]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 5 is \"+str(score))\n",
    "    return score  \n",
    "    \n",
    "def lda_user2_session6():\n",
    "    train_ids = [2003, 2004, 2005, 2001, 2007, 2008, 2009, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2006]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 6 is \"+str(score))\n",
    "    return score   \n",
    "    \n",
    "def lda_user2_session7():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2001, 2008, 2009, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2007]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 7 is \"+str(score))\n",
    "    return score     \n",
    "    \n",
    "def lda_user2_session8():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2001, 2009, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2008]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 8 is \"+str(score))\n",
    "    return score \n",
    "    \n",
    "def lda_user2_session9():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2001, 2010, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2009]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 9 is \"+str(score))\n",
    "    return score   \n",
    "    \n",
    "def lda_user2_session10():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2001, 2012, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2010]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 10 is \"+str(score))\n",
    "    return score     \n",
    "    \n",
    "def lda_user2_session12():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2001, 2013,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2012]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 12 is \"+str(score))\n",
    "    return score \n",
    "    \n",
    "def lda_user2_session13():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2028, 2029, 2031, 2032] \n",
    "    test_ids = [2013]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 13 is \"+str(score))\n",
    "    return score   \n",
    "    \n",
    "def lda_user2_session28():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2013, 2029, 2031, 2032] \n",
    "    test_ids = [2028]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 28 is \"+str(score))\n",
    "    return score  \n",
    "    \n",
    "def lda_user2_session29():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2028, 2013, 2031, 2032] \n",
    "    test_ids = [2029]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 29 is \"+str(score))\n",
    "    return score     \n",
    "    \n",
    "def lda_user2_session31():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2028, 2029, 2013, 2032] \n",
    "    test_ids = [2031]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 31 is \"+str(score))\n",
    "    return score  \n",
    "    \n",
    "def lda_user2_session32():\n",
    "    train_ids = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 2001,\n",
    "       2028, 2029, 2031, 2013] \n",
    "    test_ids = [2032]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 32 is \"+str(score))\n",
    "    return score \n",
    "    \n",
    "def lda_user4_session1():\n",
    "    train_ids = [4002]\n",
    "    test_ids = [4001]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 1 is \"+str(score))\n",
    "    return score   \n",
    "    \n",
    "def lda_user4_session2():\n",
    "    train_ids = [4001]\n",
    "    test_ids = [4002]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 2 is \"+str(score))\n",
    "    return score \n",
    "    \n",
    "def lda_user7_session1():\n",
    "    train_ids = [7002]\n",
    "    test_ids = [7001]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 1 is \"+str(score))\n",
    "    return score \n",
    "    \n",
    "def lda_user7_session2():\n",
    "    train_ids = [7001]\n",
    "    test_ids = [7002]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 2 is \"+str(score))\n",
    "    return score \n",
    "    \n",
    "def lda_user8_session2():\n",
    "    train_ids = [8003, 8010, 8016, 8017, 8018, 8019]\n",
    "    test_ids = [8002]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 2 is \"+str(score))\n",
    "    return score   \n",
    "    \n",
    "def lda_user8_session3():\n",
    "    train_ids = [8002, 8010, 8016, 8017, 8018, 8019]\n",
    "    test_ids = [8003]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 3 is \"+str(score))\n",
    "    return score  \n",
    "    \n",
    "def lda_user8_session10():\n",
    "    train_ids = [8003, 8002, 8016, 8017, 8018, 8019]\n",
    "    test_ids = [8010]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 10 is \"+str(score))\n",
    "    return score   \n",
    "    \n",
    "def lda_user8_session16():\n",
    "    train_ids = [8003, 8010, 8002, 8017, 8018, 8019]\n",
    "    test_ids = [8016]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 16 is \"+str(score))\n",
    "    return score    \n",
    "    \n",
    "def lda_user8_session17():\n",
    "    train_ids = [8003, 8010, 8016, 8002, 8018, 8019]\n",
    "    test_ids = [8017]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 17 is \"+str(score))\n",
    "    return score  \n",
    "    \n",
    "def lda_user8_session18():\n",
    "    train_ids = [8003, 8010, 8016, 8017, 8002, 8019]\n",
    "    test_ids = [8018]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 18 is \"+str(score))\n",
    "    return score     \n",
    "    \n",
    "def lda_user8_session19():\n",
    "    train_ids = [8003, 8010, 8016, 8017, 8018, 8002]\n",
    "    test_ids = [8019]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = RandomForestClassifier()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    score = k_clf.score(X_test, y_test)\n",
    "    print(\"Accuracy for session 19 is \"+str(score))\n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_all():\n",
    "    print (\"User 1 : \" )\n",
    "    #a = lda_user1_session1()\n",
    "    #b = lda_user1_session2()\n",
    "    #c = lda_user1_session3()\n",
    "    print (\"User 2 : \" )\n",
    "    d = lda_user2_session1()\n",
    "    e = lda_user2_session3()\n",
    "    f = lda_user2_session4()\n",
    "    g = lda_user2_session5()\n",
    "    h = lda_user2_session6()\n",
    "    i = lda_user2_session7()\n",
    "    j = lda_user2_session8()\n",
    "    k = lda_user2_session9()\n",
    "    l = lda_user2_session10()\n",
    "    m = lda_user2_session12()\n",
    "    n = lda_user2_session13()\n",
    "    o = lda_user2_session28()\n",
    "    p = lda_user2_session29()\n",
    "    q = lda_user2_session31()\n",
    "    r = lda_user2_session32()\n",
    "    print (\"User 4 : \" )\n",
    "   # s = lda_user4_session1()\n",
    "   # t = lda_user4_session2()\n",
    "    print (\"User 7 : \" )\n",
    "   # u = lda_user7_session1()\n",
    "   # v = lda_user7_session2()\n",
    "    print (\"User 8 : \" )\n",
    "    w = lda_user8_session2()\n",
    "    x = lda_user8_session3()\n",
    "    y = lda_user8_session10()\n",
    "    z = lda_user8_session16()\n",
    "    aa = lda_user8_session17()\n",
    "    bb = lda_user8_session18()\n",
    "    cc = lda_user8_session19()\n",
    "    scores = np.array([d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,w,x,y,z,aa,bb,cc])\n",
    "    print(\"Durchschnitt:\")\n",
    "    print(scores.mean())\n",
    "    print(scores.std())\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple():\n",
    "    scores = np.array([])\n",
    "    for i in range (21):\n",
    "        test = lda_all()\n",
    "        scores = np.concatenate([scores,test],axis=0)\n",
    "    print(\"Durchschnitt:\")\n",
    "    print((scores.mean()))\n",
    "    print(scores.std())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 : \n",
      "User 2 : \n",
      "Accuracy for session 1 is 0.49333333333333335\n",
      "Accuracy for session 3 is 0.7333333333333333\n",
      "Accuracy for session 4 is 0.37333333333333335\n",
      "Accuracy for session 5 is 0.5933333333333334\n",
      "Accuracy for session 6 is 0.7933333333333333\n",
      "Accuracy for session 7 is 0.6066666666666667\n",
      "Accuracy for session 8 is 0.6666666666666666\n",
      "Accuracy for session 9 is 0.6066666666666667\n",
      "Accuracy for session 10 is 0.7666666666666667\n",
      "Accuracy for session 12 is 0.58\n",
      "Accuracy for session 13 is 0.34\n",
      "Accuracy for session 28 is 0.44\n",
      "Accuracy for session 29 is 0.6333333333333333\n",
      "Accuracy for session 31 is 0.4666666666666667\n",
      "Accuracy for session 32 is 0.3466666666666667\n",
      "User 4 : \n",
      "User 7 : \n",
      "User 8 : \n",
      "Accuracy for session 2 is 0.64\n",
      "Accuracy for session 3 is 0.5666666666666667\n",
      "Accuracy for session 10 is 0.5066666666666667\n",
      "Accuracy for session 16 is 0.5466666666666666\n",
      "Accuracy for session 17 is 0.5733333333333334\n",
      "Accuracy for session 18 is 0.58\n",
      "Accuracy for session 19 is 0.6\n",
      "Durchschnitt:\n",
      "0.566060606060606\n",
      "0.12003213527477793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.49333333, 0.73333333, 0.37333333, 0.59333333, 0.79333333,\n",
       "       0.60666667, 0.66666667, 0.60666667, 0.76666667, 0.58      ,\n",
       "       0.34      , 0.44      , 0.63333333, 0.46666667, 0.34666667,\n",
       "       0.64      , 0.56666667, 0.50666667, 0.54666667, 0.57333333,\n",
       "       0.58      , 0.6       ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "61"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
