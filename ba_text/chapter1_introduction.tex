\chapter{Vorstellung}
Die gesprochene Sprache ist das wichtigste zwischenmenschliche Kommunikationsmedium. Wir kommunizieren aber nicht nur Fakten mit der Sprache, sondern auch paralinguistische Informationen.
Jedoch kann es Situationen geben, in denen man Informationen über die Sprache weitergeben muss, dies jedoch aus verschiedenen Gründen nicht möglich ist. In Deutschland alleine leben nach dem Statistischen Bundesamt \cite{StatBund} über 300.000 Menschen mit Sprach- oder Sprechstörungen. Für viele dieser Personen ist das Einstellen einer privaten Hilfe nicht möglich. Für diese Menschen soll es möglich sein, auf Sprache basierende Schnittstellen ohne Probleme zu nutzen. Dies soll dadurch ermöglicht werden, dass biologisches Signale betrachtet werden, welche in den Muskeln während dem Reden produziert werden. Genauer geht es um die elektrischen Biosignale der Gesichtsmuskeln beim Produzieren der Sprache und ob diese genutzt werden können, um den Sprachmodus sowie die Identität zu bestimmen.


\paragraph{}
Eine Anwendungsweise dieser Signale sind heutzutage die sogenannten SSIs (Silent Speech Interfaces), die zum Beispiel im Militär \cite{6415781} für strategische Zwecke genutzt werden. Eine weitere Möglichkeit stummen Menschen zu helfen ist die elektrische Stimulation der Mundmuskeln. In \cite{schultz_embc_2019} zeigen Schultz et al., wie Funktionelle elektrische Stimulation (FES) genutzt werden können, um die Sprachmuskeln effektiv zu steuern.
Des Weiteren wird durch Brain Computer Interfaces versucht die Sprache zu rekonstruieren. Also das Gedachte wird direkt in Sprache umgewandelt. Dazu wurden in dieser Doktorarbeit von Christian Emanuel Herf zwei verschiedene Technologien (fNIRS und ECoG)vorgestellt. \cite{herff2016speech} 

Ich hoffe, dass diese Arbeit die Qualität und Genauigkeit solcher SSIs, durch das Vorhersagen der Identität und des Sprachmodus verbessern kann. Der Sprachmodus kann dabei vor der Generierung der eigentlichen Sprache erkannt werden\cite{Tanja_Interspeechkeynote_2019}.
In dieser Arbeit wird geprüft, ob das Erkennen der Identität sowie des Sprachmodus durch Oberflächen-EMG Daten möglich ist. Dazu werden die Daten des UKA Korpus des CSL der Uni Bremen verwendet (\cite{WaJaSch2014-IS}).

\section{Umfang der Arbeit}
Es werden verschiedene Klassifikatoren in der Scikit-learn Umgebung verwendet, um die Identität sowie den Sprachmodus des Sprechers vorherzusagen. Zudem wird versucht durch das Entfernen von einzelnen Sessions und durch Filtern das Resultat so hoch wie möglich zu bekommen.


\section{Verwandte Arbeit}
\paragraph{}
Die Verwendung von EMG zur Spracherkennung geht zurück auf
die 1980er Jahre. Die ersten Wettbewerbsfähigen Erkenner stammen jedoch jedoch von Chan et al. aus 2001, welche eine durchschnittliche Wortgenauigkeit von 93 Prozent für einem 10-Wort-Vokabular aus englischen Ziffern geschafft haben. Jorgensen et al. haben es 2003 ebenfalls geschafft gute Leistungen bei schweigendem Sprechen der Worte zu erreichen. Dies deutet darauf hin, dass diese Technologie
für Silent Speech-Schnittstellen verwendet werden \cite{inproceedings}.

In den INTERSPEECH Konferenzen geht es um die Erkennung verschiedener paralinguistischer Merkmale. (\cite{ISCA2020-SP})
In \cite{janke2011investigations} geht es zum Beispiel, um die Möglichkeit durch phonetische Entscheidungsbäume zwischen dem stummen und normalen Sprachmodus zu unterscheiden. In dieser Arbeit wird ebenfalls der UKA-Korpus der CSL Bremen verwendet. Hier wird gezeigt,dass es möglich ist einen Erkenner mit stummen sowie hörbaren Daten gleichzeitig zu trainieren. Das macht es einfacher während des Erkennungsprozesses den zu erkennenden Sprachmodus zu wechseln. Es werden hier zudem Genauigkeiten für einzelne Phoneme analysiert.

In \cite{article} werden die verschiedenen Möglichkeiten, die Stimme einer Person durch Silent Speech Interfaces wiederherzustellen, untersucht.In dem Der Artikel gibt  einen Überblick über die jüngsten Versuche, Sprache aus nicht-akustischen Biosignalen, die während der Sprachproduktion erzeugt werden, zu entschlüsseln.
 
Die Autoren präsentieren eine umfassende Liste von Sensortechnologien, die derzeit zur Erfassung von Biosignalen, einschließlich invasiver und nicht invasiver Techniken in Erwägung gezogen werden. Aus diesen Biosignalen kann Sprache dekodiert werden. Das passiert entweder durch automatische Spracherkennung oder durch direkte
Sprachsynthese. Ein potenzieller Vorteil des letzteren Ansatzes
ist, dass sie möglicherweise die Entschlüsselung von Sprache in Echtzeit ermöglicht. Dies könnte dazu beitragen in der Zukunft die Stimme einer Person wiederherzustellen. 

Bei weiteren Arbeiten zum Thema SSIs gibt es zum Beispiel \cite{8114359} sowie andere Arbeiten des CSL Bremen. Das CSL Bremen hat eine große Sammlung an Arbeiten in denen verschiedene Technologien in dieser Richtung ausprobiert wurden. In \cite{wand2013artifact} zum Beispiel wird ein ICA Algorithmus genutzt um Artefakte in einem stummen Spracherkenner zu verringern. In \cite{janke2010spectral} zeigten Janke et al., dass EMG-Signale von hörbarer Sprache im Allgemeinen eine höhere spektrale Leistung als EMG-Signale von stummer Sprache, aufweisen. Mit diesen Informationen konnte eine Abbildung vom stillen zum hörbaren/geflüsterten EMG erreicht werden, was zu einer 12,3 prozentigen Verbesserung führte.

\clearpage
In \cite{8114358} haben Schultz et al. die verschiedenen Biosignale bei der Erzeugung von Sprache beschrieben und zudem das Potenzial dieser Signale für das Bauen eines Biosignal basierten Spracherkenners analysiert. Das wäre ein Spracherkenner welcher alle möglichen Biosignale benutzt,  um einen Spracherkenner so genau wie möglich zu gestalten.
In \cite{diener2020towards} wurden der Sprachmodus und die Sprecheridentität mit einem anderen Korpus des CSL vorhergesagt. Dieser Korpus wurde mit einem Array Elektrodensetup anstatt Einzelelektroden aufgenommen. In dieser Arbeit wird AUDEEP genutzt \cite{AUDEEP-GIT}. 

\section{Struktur}
Der Rest des Dokuments ist folgendermaßen aufgebaut:


Kapitel 2 stellt vor worauf diese Arbeit basiert und stellt die nötigen biologischen sowie technischen Elemente dar. 



In Kapitel 3 wird der Versuchsaufbau, mit der die späteren Versuche durchgeführt werden, vorgestellt. 



In Kapitel 4 sind die Ergebnisse der in Kapitel 3 genannten Versuche zu sehen. 


In Kapitel 5 werden die Ergebnisse noch einmal zusammengefasst und näher analysiert. 


Am Ende in Kapitel 6 wird beschrieben, was die Funde meiner Meinung nach bedeuten. Zudem sind in diesem Kapitel Vorschläge für weitere Verbesserungen zu finden.