{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magomed\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Features_10hz_200hz_mav2.csv' does not exist: b'Features_10hz_200hz_mav2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dbe4288d662f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Features_10hz_200hz_mav2.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'channel_1_medf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Features_10hz_200hz_mav2.csv' does not exist: b'Features_10hz_200hz_mav2.csv'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.fftpack import fftn, ifftn, fft, ifft\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') \n",
    "df = pd.read_csv(\"unfilteredFeatures_aud.csv.csv\")\n",
    "\n",
    "df = df.drop ('channel_1_medf', axis=1)\n",
    "df = df.drop ('channel_2_medf', axis=1)\n",
    "df = df.drop ('channel_3_medf', axis=1)\n",
    "df = df.drop ('channel_4_medf', axis=1)\n",
    "df = df.drop ('channel_5_medf', axis=1)\n",
    "df = df.drop ('channel_6_medf', axis=1)\n",
    "\n",
    "df = df.drop ('channel_1_var', axis=1)\n",
    "df = df.drop ('channel_2_var', axis=1)\n",
    "df = df.drop ('channel_3_var', axis=1)\n",
    "df = df.drop ('channel_4_var', axis=1)\n",
    "df = df.drop ('channel_5_var', axis=1)\n",
    "df = df.drop ('channel_6_var', axis=1)\n",
    "\n",
    "#dfs = df[(df.modeID != 'audible')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_per_session(session_id):\n",
    "    temp_df = df[(df.sessionID == session_id)]\n",
    "    data = temp_df.copy()\n",
    "    data = shuffle(data)\n",
    "    y = data['modeID']\n",
    "    data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "def split_data_session(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['sessionID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['sessionID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['userID']\n",
    "    y_test = X_test['userID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def split_data_utterance(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['userID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['userID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['userID']\n",
    "    y_test = X_test['userID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def split_data(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['userID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['userID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda():\n",
    "    ids = [1001,1002,1003,2001,2002,2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,2011, 2012, 2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,\n",
    "        2023,2024,2025,2026,2027,2028, 2029, 2030,2031, 2032,2101,8001,8002,8003,8004,8005,8006,8007,8008,8009, 8010, 8011,8012,8013,8014,8015, 8016, 8017, 8018,8019, 8101]\n",
    "    scores = np.array([])\n",
    "    for x in range (len(ids)):\n",
    "        test_ids = []\n",
    "        test_ids = ids[x:x+1]\n",
    "        train_ids = np.delete(ids,x)\n",
    "        #print (test_ids)\n",
    "        X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "        k_clf = LinearDiscriminantAnalysis()\n",
    "        k_clf.fit(X_train, y_train)\n",
    "        score = k_clf.score(X_test, y_test)\n",
    "        sscore = np.array([score])\n",
    "        scores = np.concatenate([scores,sscore],axis=0)\n",
    "        print(\"Accuracy for session \" + str(test_ids) +\" is \"+str(score))\n",
    "    print (\"Durchschnitt: \")\n",
    "    print((scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for session [1001] is 0.78\n",
      "Accuracy for session [1002] is 0.6933333333333334\n",
      "Accuracy for session [1003] is 0.9\n",
      "Accuracy for session [2001] is 0.9866666666666667\n",
      "Accuracy for session [2002] is 1.0\n",
      "Accuracy for session [2003] is 0.9533333333333334\n",
      "Accuracy for session [2004] is 0.9866666666666667\n",
      "Accuracy for session [2005] is 0.9133333333333333\n",
      "Accuracy for session [2006] is 0.94\n",
      "Accuracy for session [2007] is 0.9466666666666667\n",
      "Accuracy for session [2008] is 0.96\n",
      "Accuracy for session [2009] is 0.9533333333333334\n",
      "Accuracy for session [2010] is 1.0\n",
      "Accuracy for session [2011] is 0.82\n",
      "Accuracy for session [2012] is 0.9866666666666667\n",
      "Accuracy for session [2013] is 0.98\n",
      "Accuracy for session [2014] is 1.0\n",
      "Accuracy for session [2015] is 0.98\n",
      "Accuracy for session [2016] is 0.94\n",
      "Accuracy for session [2017] is 1.0\n",
      "Accuracy for session [2018] is 1.0\n",
      "Accuracy for session [2019] is 1.0\n",
      "Accuracy for session [2020] is 0.96\n",
      "Accuracy for session [2021] is 1.0\n",
      "Accuracy for session [2022] is 0.98\n",
      "Accuracy for session [2023] is 1.0\n",
      "Accuracy for session [2024] is 1.0\n",
      "Accuracy for session [2025] is 0.98\n",
      "Accuracy for session [2026] is 0.58\n",
      "Accuracy for session [2027] is 0.97\n",
      "Accuracy for session [2028] is 1.0\n",
      "Accuracy for session [2029] is 0.54\n",
      "Accuracy for session [2030] is 1.0\n",
      "Accuracy for session [2031] is 1.0\n",
      "Accuracy for session [2032] is 0.9466666666666667\n",
      "Accuracy for session [2101] is 0.9961538461538462\n",
      "Accuracy for session [8001] is 0.98\n",
      "Accuracy for session [8002] is 0.9266666666666666\n",
      "Accuracy for session [8003] is 0.7333333333333333\n",
      "Accuracy for session [8004] is 0.82\n",
      "Accuracy for session [8005] is 0.52\n",
      "Accuracy for session [8006] is 0.8\n",
      "Accuracy for session [8007] is 0.94\n",
      "Accuracy for session [8008] is 0.82\n",
      "Accuracy for session [8009] is 0.98\n",
      "Accuracy for session [8010] is 0.9733333333333334\n",
      "Accuracy for session [8011] is 0.98\n",
      "Accuracy for session [8012] is 1.0\n",
      "Accuracy for session [8013] is 1.0\n",
      "Accuracy for session [8014] is 0.96\n",
      "Accuracy for session [8015] is 0.86\n",
      "Accuracy for session [8016] is 0.9866666666666667\n",
      "Accuracy for session [8017] is 0.98\n",
      "Accuracy for session [8018] is 1.0\n",
      "Accuracy for session [8019] is 0.9266666666666666\n",
      "Accuracy for session [8101] is 0.9233791748526523\n",
      "Durchschnitt: \n",
      "0.9246940420417827\n"
     ]
    }
   ],
   "source": [
    "lda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
