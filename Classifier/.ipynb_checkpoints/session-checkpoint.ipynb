{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magomed\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.fftpack import fftn, ifftn, fft, ifft\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') \n",
    "df = pd.read_csv(\"Features_all.csv\")\n",
    "a = np.unique(df.userID)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_per_session(session_id):\n",
    "    temp_df = df[(df.sessionID == session_id)]\n",
    "    data = temp_df.copy()\n",
    "    y = data['sessionID']\n",
    "    data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return train_test_split(data, y, test_size=0.25)\n",
    "\n",
    "def split_data():\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    y = data['sessionID']\n",
    "    data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return train_test_split(data, y, test_size=0.25)\n",
    "\n",
    "def split_data():\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    y = data['sessionID']\n",
    "    data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return train_test_split(data, y, test_size=0.25)\n",
    "\n",
    "def split_data_per_user(user_id):\n",
    "    temp_df = df[(df.userID == user_id)]\n",
    "    sessionIDs = np.unique(temp_df.sessionID)\n",
    "    x1 = pd.DataFrame()\n",
    "    x2 = pd.DataFrame()\n",
    "    y1 = pd.DataFrame()\n",
    "    y2 = pd.DataFrame()\n",
    "    for sessionID in sessionIDs:\n",
    "        temp_dfs = temp_df[(temp_df.sessionID == sessionID)]\n",
    "        data = temp_dfs.copy()\n",
    "        y = data['userID']\n",
    "        data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "        w,x,y,z = train_test_split(data, y, test_size=0.2)\n",
    "        x1 = x1.append(w)\n",
    "        x2 = x2.append(x)\n",
    "        #print(y,y1)\n",
    "        y1 = pd.concat([y1,y])\n",
    "        y2 = pd.concat([y2,z])\n",
    "    return x1,x2,y1,y2\n",
    "\n",
    "def split_data2():\n",
    "    temp_df = df\n",
    "    sessionIDs = np.unique(df.sessionID)\n",
    "    x1 = pd.DataFrame()\n",
    "    x2 = pd.DataFrame()\n",
    "    y1 = pd.DataFrame()\n",
    "    y2 = pd.DataFrame()\n",
    "    for sessionID in sessionIDs:\n",
    "        temp_dfs = temp_df[(temp_df.sessionID == sessionID)]\n",
    "        data = temp_dfs.copy()\n",
    "        y = data['sessionID']\n",
    "        data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "        w,x,y,z = train_test_split(data, y, test_size=0.1)\n",
    "        x1 = x1.append(w)\n",
    "        x2 = x2.append(x)\n",
    "        #print(y,y1)\n",
    "        y1 = pd.concat([y1,y])\n",
    "        y2 = pd.concat([y2,z])\n",
    "    return x1,x2,y1,y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_all_users_separately():\n",
    "    user_ids = np.unique(df.userID)\n",
    "    for user_id in user_ids:\n",
    "        X_train, X_test, y_train, y_test = split_data_per_user(user_id)\n",
    "        clf = LinearDiscriminantAnalysis()\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(\"Accuracy for user \" + str(user_id) + \" is \" + str(clf.score(X_test, y_test)))\n",
    "\n",
    "def lda_all():\n",
    "    X_train, X_test, y_train, y_test = split_data2()\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Accuracy for all users is \"+str(clf.score(X_test, y_test)))\n",
    "    \n",
    "def lda_all_sessions_separately():\n",
    "    sessionIDs = np.unique(df.sessionID)\n",
    "    for sessionID in sessionIDs:\n",
    "        X_train, X_test, y_train, y_test = split_data_per_session(sessionID)\n",
    "        print((y_train))\n",
    "        clf = LinearDiscriminantAnalysis()\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(\"Accuracy for session \" + str(sessionID) + \" is \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for all users is 0.7262872628726287\n"
     ]
    }
   ],
   "source": [
    "lda_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Die Session mit einem Score von 1.0 \n",
    "#sind Sessions die jediglich 'Audible' audios enthalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "7      1001\n",
      "83     1001\n",
      "60     1001\n",
      "113    1001\n",
      "22     1001\n",
      "       ... \n",
      "23     1001\n",
      "105    1001\n",
      "103    1001\n",
      "148    1001\n",
      "70     1001\n",
      "Name: sessionID, Length: 120, dtype: int64\n",
      "          0\n",
      "7    1001.0\n",
      "83   1001.0\n",
      "60   1001.0\n",
      "113  1001.0\n",
      "22   1001.0\n",
      "..      ...\n",
      "23   1001.0\n",
      "105  1001.0\n",
      "103  1001.0\n",
      "148  1001.0\n",
      "70   1001.0\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "278    1002\n",
      "188    1002\n",
      "282    1002\n",
      "259    1002\n",
      "241    1002\n",
      "       ... \n",
      "210    1002\n",
      "165    1002\n",
      "203    1002\n",
      "281    1002\n",
      "258    1002\n",
      "Name: sessionID, Length: 120, dtype: int64\n",
      "          0\n",
      "7    1001.0\n",
      "83   1001.0\n",
      "60   1001.0\n",
      "113  1001.0\n",
      "22   1001.0\n",
      "..      ...\n",
      "210  1002.0\n",
      "165  1002.0\n",
      "203  1002.0\n",
      "281  1002.0\n",
      "258  1002.0\n",
      "\n",
      "[240 rows x 1 columns]\n",
      "335    1003\n",
      "376    1003\n",
      "343    1003\n",
      "426    1003\n",
      "414    1003\n",
      "       ... \n",
      "346    1003\n",
      "408    1003\n",
      "337    1003\n",
      "370    1003\n",
      "433    1003\n",
      "Name: sessionID, Length: 120, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "temp_df = df[(df.userID == 1)]\n",
    "sessionIDs = np.unique(temp_df.sessionID)\n",
    "x1 = pd.DataFrame()\n",
    "x2 = pd.DataFrame()\n",
    "y1 = pd.DataFrame()\n",
    "y2 = pd.DataFrame()\n",
    "for sessionID in sessionIDs:\n",
    "    temp_dfs = temp_df[(temp_df.sessionID == sessionID)]\n",
    "    data = temp_dfs.copy()\n",
    "    y = data['sessionID']\n",
    "    data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    w,x,y,z = train_test_split(data, y, test_size=0.2)\n",
    "    print((y1))\n",
    "    print(y)\n",
    "    x1 = x1.append(w)\n",
    "    x2 = x2.append(x)\n",
    "    y1 = pd.concat([y1,y])\n",
    "    y2 = y2.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
