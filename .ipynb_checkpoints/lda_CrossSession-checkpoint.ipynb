{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magomed\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0b5fdd67a8f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Features_all_no_audible.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodeID\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'audible'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dfs' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.fftpack import fftn, ifftn, fft, ifft\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') \n",
    "df = pd.read_csv(\"Features_all_no_audible.csv\")\n",
    "dfs = df[(dfs.modeID != 'audible')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_per_session(session_id):\n",
    "    temp_df = df[(df.sessionID == session_id)]\n",
    "    data = temp_df.copy()\n",
    "    data = shuffle(data)\n",
    "    y = data['modeID']\n",
    "    data.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "def split_data_session(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['sessionID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['sessionID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['userID']\n",
    "    y_test = X_test['userID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def split_data_utterance(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['userID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['userID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def split_data(train_user_ids,test_user_ids):\n",
    "    temp_df = df\n",
    "    data = temp_df.copy()\n",
    "    train_df = data.loc[data['userID'].isin(train_user_ids)]\n",
    "    test_df = data.loc[data['userID'].isin(test_user_ids)]\n",
    "    X_train = train_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    y_train = X_train['modeID']\n",
    "    y_test = X_test['modeID']\n",
    "    X_train.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    X_test.drop(labels=['userID','uttID', 'sessionID','modeID'], axis=1, inplace=True)\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lda_all_users_separately():\n",
    "    user_ids = np.unique(df.userID)\n",
    "    for user_id in user_ids:\n",
    "        X_train, X_test, y_train, y_test = split_data_per_user(user_id)\n",
    "        k_clf = LinearDiscriminantAnalysis()\n",
    "        k_clf.fit(X_train, y_train)\n",
    "        score = k_clf.score(X_test, y_test)\n",
    "        print(\"Accuracy for user \" + str(user_id) + \" is \" + str(k_clf.score(X_test, y_test)))\n",
    "\n",
    "def lda_all():\n",
    "    train_ids = [1,2,3,4,5,6,7]\n",
    "    test_ids = [8]\n",
    "    X_train, X_test, y_train, y_test = split_data(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    k_clf.fit(X_train, y_train)\n",
    "    scores = cross_val_score(k_clf,X_test,y_test,cv=10)\n",
    "    print(\"Accuracy for all users is \"+str(k_clf.score(X_test, y_test)))\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "def lda_all_sessions_separately():\n",
    "    sessionIDs = np.unique(df.sessionID)\n",
    "    for sessionID in sessionIDs:\n",
    "        X_train, X_test, y_train, y_test = split_data_per_session(sessionID)\n",
    "        k_clf = LinearDiscriminantAnalysis()\n",
    "        k_clf.fit(X_train, y_train)\n",
    "        score = k_clf.score(X_test, y_test)\n",
    "        scores = cross_val_score(k_clf,X_test,y_test,cv=2,scoring='f1_macro')\n",
    "        print(\"Accuracy for session \" + str(sessionID) + \" is \" + str(score))\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "def lda_all_sessions():\n",
    "    train_ids = [8002,8003,8010,8016,8017,8019]\n",
    "    test_ids = [8018]\n",
    "    X_train, X_test, y_train, y_test = split_data_session(train_ids,test_ids)\n",
    "    k_clf = LinearDiscriminantAnalysis()\n",
    "    parameter_grid = {}\n",
    "    clf = GridSearchCV(k_clf, parameter_grid, cv=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores = cross_val_score(k_clf,X_test,y_test,cv=10)\n",
    "    print(\"Accuracy for all users is \"+str(clf.score(X_test, y_test)))\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for all users is 1.0\n",
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "lda_all_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for all users is 0.5257142857142857\n",
      "Accuracy: 0.66 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "lda_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
